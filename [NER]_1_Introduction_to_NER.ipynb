{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NER] 1. Introduction to NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJpRtPt0Hv4p",
        "colab_type": "text"
      },
      "source": [
        "# Introduction To NER\n",
        "\n",
        "![대체 텍스트](https://i.imgur.com/kcucuJ6.png)\n",
        "\n",
        "개체명 인식(Named Entity Recognition, NER)이란 '이름을 가진 개체(named entity)'를 찾아내고 이를 인명, 기관명, 지명 등의 유형으로 인식하는 것을 말합니다. \n",
        "\n",
        "각 개체명은 문장 또는 문서에서 특정한 의미를 가지기 때문에 정보 검색 및 언어 이해를 위한 분석에서 주요한 대상으로 다뤄집니다. \n",
        "\n",
        "본 글은 NER를 이해하기 위한 시리즈의 첫 번째 글로 앞으로의 글 목록은 다음과 같습니다:\n",
        "\n",
        "1. Introduction To NER\n",
        "2. NER With CRF In Python\n",
        "3. NER with LSTM\n",
        "4. Sequence Tagging With A LSTM-CRF\n",
        "... \n",
        "\n",
        "데이터셋은 [kaggle](https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus)에서 가져왔습니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWhgriJUHnhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"/content/ner_dataset.csv\", encoding='latin1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm9Xo_59MKM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 빈 값을 앞 데이터로부터 채우기\n",
        "# https://ordo.tistory.com/59\n",
        "\n",
        "data = data.fillna(method=\"ffill\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GISBc911QLN9",
        "colab_type": "code",
        "outputId": "f22780c6-3d3e-4990-80b0-644df8886857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "data.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048565</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>impact</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048566</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048567</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>Indian</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048568</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>forces</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048569</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>said</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>attack</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Sentence #       Word  POS    Tag\n",
              "1048565  Sentence: 47958     impact   NN      O\n",
              "1048566  Sentence: 47958          .    .      O\n",
              "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
              "1048568  Sentence: 47959     forces  NNS      O\n",
              "1048569  Sentence: 47959       said  VBD      O\n",
              "1048570  Sentence: 47959       they  PRP      O\n",
              "1048571  Sentence: 47959  responded  VBD      O\n",
              "1048572  Sentence: 47959         to   TO      O\n",
              "1048573  Sentence: 47959        the   DT      O\n",
              "1048574  Sentence: 47959     attack   NN      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGG8L-AaQNmX",
        "colab_type": "code",
        "outputId": "c2b3c838-df1f-4d21-f9e6-33dba5d6652a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "n_words = len(words)\n",
        "\n",
        "print(n_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8Wcz-_iQm4g",
        "colab_type": "text"
      },
      "source": [
        "data.tail()과 n_words를 통해 알아낸 데이터의 특징:\n",
        "- 문장의 개수: 46,959개\n",
        "- 단어 개수 : 35,178개\n",
        "\n",
        "그렇다면 이제 데이터를 [문장] : [POS] : [NER]의 형태로 만들어봅시다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKpN6POgQl0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GetSentencePair(data):\n",
        "    n_sent = 1\n",
        "    s = data[data[\"Sentence #\"] == \"Sentence: {}\".format(n_sent)]\n",
        "    n_sent +=1\n",
        "    return s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZxqb9WASPy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent, pos, tag = GetSentencePair(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5oPC4VOSUkc",
        "colab_type": "code",
        "outputId": "36024de8-59de-45dd-d1e1-eebfe9f3ba36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(sent)\n",
        "print(pos)\n",
        "print(tag)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etlGeY-5TSL4",
        "colab_type": "text"
      },
      "source": [
        "## A simple machine learning approach\n",
        "\n",
        "첫 단계로 단어를 모두 벡터로 바꾸어주어야 합니다. \n",
        "그 후, 사이킷런(sklearn)의 랜덤 포레스트 분류기(RamdomForestClassifier)를 이용해 단어를 분류합니다.\n",
        "\n",
        "랜덤 포레스트를 이용하기 위해 각 단어의 피쳐들을 선정해 값을 넣어줄 것입니다. \n",
        "\n",
        "고려하는 피쳐의 목록은 다음과 같습니다:\n",
        "- word.istitle() : 대문자로 시작\n",
        "- word.islower() : 모든 문자 소문자\n",
        "- word.isupper() : 모든 문자 대문자\n",
        "- len(word) : 단어 길이\n",
        "- word.isdigit()  : 숫자\n",
        "- word.isalpha() : 알파벳\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzRMbkexSZAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VyJGpzVjOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_map(word):\n",
        "    '''Simple feature map.'''\n",
        "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
        "                     word.isdigit(),  word.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lfd34LKSVk6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [feature_map(word) for word in data[\"Word\"].values.tolist()]\n",
        "tags = data[\"Tag\"].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMGK59SHWGGx",
        "colab_type": "code",
        "outputId": "b109838d-10ae-49fc-e59a-5d9199ab0b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(words[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 9 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN1itbtBWHfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X: The data to fit \n",
        "# y: The target variable to try to predict\n",
        "# cv : Determines the cross-validation splitting strategy.  5-fold cross validation\n",
        "\n",
        "pred = cross_val_predict(RandomForestClassifier(n_estimators=20), X= words, y=tags, cv=5)\n",
        "                                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkvfHQh0W7KQ",
        "colab_type": "code",
        "outputId": "460e28c1-eb9c-4f0c-b8a5-94f99c3bad6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "report = classification_report(y_pred=pred, y_true=tags)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY_0ib0bXr2_",
        "colab_type": "code",
        "outputId": "94c2f3b7-1f66-496c-8730-501ef751eb6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00       402\n",
            "       B-eve       0.00      0.00      0.00       308\n",
            "       B-geo       0.26      0.79      0.40     37644\n",
            "       B-gpe       0.25      0.06      0.09     15870\n",
            "       B-nat       0.00      0.00      0.00       201\n",
            "       B-org       0.65      0.17      0.27     20143\n",
            "       B-per       0.96      0.20      0.33     16990\n",
            "       B-tim       0.29      0.32      0.30     20333\n",
            "       I-art       0.00      0.00      0.00       297\n",
            "       I-eve       0.00      0.00      0.00       253\n",
            "       I-geo       0.00      0.00      0.00      7414\n",
            "       I-gpe       0.00      0.00      0.00       198\n",
            "       I-nat       0.00      0.00      0.00        51\n",
            "       I-org       0.36      0.03      0.06     16784\n",
            "       I-per       0.47      0.02      0.04     17251\n",
            "       I-tim       0.50      0.06      0.11      6528\n",
            "           O       0.97      0.98      0.97    887908\n",
            "\n",
            "    accuracy                           0.87   1048575\n",
            "   macro avg       0.28      0.15      0.15   1048575\n",
            "weighted avg       0.88      0.87      0.86   1048575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uEBOUjKYDeT",
        "colab_type": "text"
      },
      "source": [
        "결과가 매우 나쁘죠? 이는 결정에 필요한 피쳐들이 충분하지 않았기 때문입니다. 따라서, 다음 포스트에서는 보다 정교한 알고리즘을 이용해 피쳐를 선정해봅시다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5w-G1dXX4vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}