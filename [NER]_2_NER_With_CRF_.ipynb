{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[NER] 2. NER With CRF .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZoLAcoGYuB3",
        "colab_type": "text"
      },
      "source": [
        "# 2. Named Entity Recognition With Conditional Random Fields(CRF) In Python\n",
        "\n",
        "저번 포스트에서는 해당 단어만의 특징들을 이용해 NER을 수행해보았습니다. 하지만, 결과는 매우 좋지 않았죠. \n",
        "\n",
        "이번 모델에서는 맥락(context)과 구조를 활용해 NER을 수행합니다. \n",
        "\n",
        "사용할 알고리즘은 : **Conditional Random Field(CRF)**입니다. \n",
        "\n",
        "2018년 네이버와 창원대가 함께 개최한 NLP Challenge;NER 에서도 베이스라인 모델로 Bidiriectional RNN + CRF 의 조합을 사용했죠. \n",
        "\n",
        "CRF는 앞으로의 포스트에도 등장할 예정이니 열심히 학습해봅시다!\n",
        "\n",
        "\n",
        "앞으로의 포스트는 다음과 같습니다:\n",
        "1. Introduction To NER\n",
        "2. NER With CRF \n",
        "3. NER with LSTM\n",
        "4. Sequence Tagging With A LSTM-CRF\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50mkNS2CZTgJ",
        "colab_type": "text"
      },
      "source": [
        "## Conditional Random Field (CRF)\n",
        " \n",
        " Conditional Random Field(CRF)는 RNN의 등장 이전에 시퀀스 데이터를 처리하는 가장 대표적인 알고리즘입니다. \n",
        "\n",
        " CRF를 한 문장으로 정의하면 다음과 같습니다:\n",
        " > Sequential labeling 을 위하여 potential functions 을 이용하는 softmax regression\n",
        "\n",
        "Sequential Labeling이 무엇인지, Potential function이 어떤 함수인지는 **이론** 포스트를 참조하세요!\n",
        "\n",
        "간단하게만 설명하면: \n",
        "- sequential labeling은 시퀀스가 입력으로 들어갔을 때, 출력 레이블도 시퀀스로 나오는 것을 의미합니다. 결국은 분류 모델인 것이죠. \n",
        "\n",
        "- CRF의 potential function은 시퀀스 데이터를 벡터로 표현합니다. 예를 들어, 띄어쓰기가 필요한 부분은 1, 아닌 부분은 0으로 표현할 수 있죠. \n",
        "\n",
        "- Softmax Regression은 벡터 x에 대해서 label Y를 출력하는 함수입니다. \n",
        "\n",
        "CRF를 사용하는 이유는 간단합니다. CRF는 앞, 뒤의 단어로 이뤄진 **문맥**을 이용하여 labeling을 합니다. 이에 따라 코퍼스에 직접적으로 등장하지 않은 단어들에 대한 대처 능력이 상승합니다! 마치 Word2vec과 같은 이치네요!\n",
        "\n",
        "***CRF can learn context!*** \n",
        "\n",
        "그렇다면, 문맥을 고려하지 않고 해당 단어만을 살펴봤던 NER(Named Entity Recognition)이 CRF를 적용했을 때, 얼마나 성능이 올라가는지 확인해봅시다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOoN1trRX9r7",
        "colab_type": "text"
      },
      "source": [
        "## Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-JcgOpTYnxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv(\"/content/ner_dataset.csv\", encoding='latin1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KfaM9jAYN7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 빈 값을 앞 데이터로부터 채우기\n",
        "# https://ordo.tistory.com/59\n",
        "\n",
        "data = data.fillna(method = \"ffill\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ0OUd85YTEw",
        "colab_type": "code",
        "outputId": "43c92186-67d0-4acf-9505-a2e9562bcfc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "data.tail(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048565</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>impact</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048566</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048567</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>Indian</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048568</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>forces</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048569</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>said</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>attack</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Sentence #       Word  POS    Tag\n",
              "1048565  Sentence: 47958     impact   NN      O\n",
              "1048566  Sentence: 47958          .    .      O\n",
              "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
              "1048568  Sentence: 47959     forces  NNS      O\n",
              "1048569  Sentence: 47959       said  VBD      O\n",
              "1048570  Sentence: 47959       they  PRP      O\n",
              "1048571  Sentence: 47959  responded  VBD      O\n",
              "1048572  Sentence: 47959         to   TO      O\n",
              "1048573  Sentence: 47959        the   DT      O\n",
              "1048574  Sentence: 47959     attack   NN      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq6QLlguYT4t",
        "colab_type": "code",
        "outputId": "a03855f9-8128-4912-91ce-837f326f9f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "n_words = len(words)\n",
        "\n",
        "print(n_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTBCy6DZYrxo",
        "colab_type": "text"
      },
      "source": [
        "data.tail()과 n_words를 통해 알아낸 데이터의 특징:\n",
        "- 문장의 개수: 46,959개\n",
        "- 단어 개수 : 35,178개\n",
        "\n",
        "그렇다면 이제 데이터를 [문장] : [POS] : [NER]의 형태로 만들어봅시다. \n",
        "\n",
        "지난 포스트와는 달리 이번엔 pandas 라이브러리에서 제공하는 **groupby()** 메서드를 사용합니다. \n",
        "\n",
        "Python pandas의 groupby() 연산자는 그룹별로 데이터를 집계하고 요약하는데 아주 편리한 기능을 제공합니다. \n",
        "\n",
        "전체 데이터를 그룹 별로 나누고 (split), 각 그룹별로 집계함수를 적용(apply) 한후, 그룹별 집계 결과를 하나로 합치는(combine) 단계를 거치게 됩니다. (Split => Apply function => Combine)\n",
        "\n",
        "자세한 내용은 밑을 참고하세요!\n",
        "\n",
        "출처: https://rfriend.tistory.com/383 [R, Python 분석과 프로그래밍의 친구 (by R Friend)]\n",
        "\n",
        "본 포스트에서는 문장의 번호를 기준으로 나머지 데이터들의 모양을 바꾸어보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neRbl7SjYebi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GetSentencePair(object):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "\n",
        "        agg_func = lambda s: [(w,p,t) for w,p,t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"POS\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        \n",
        "        self.group = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
        "        self.sentences = [s for s in self.group]\n",
        "\n",
        "    def get_next(self):\n",
        "        try: \n",
        "            s = self.group[\"Sentence: {}\".format(self.n_next)]\n",
        "            self.n_sent +=1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCQSxTsgYgLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GetSent = GetSentencePair(data)\n",
        "sent = GetSent.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o7KMtIkbKfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = GetSent.sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UTEB0J0baSG",
        "colab_type": "code",
        "outputId": "0b79d201-e55f-4c6f-a9c9-0fb8980b4976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(sentences[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojEwR6wdbjOz",
        "colab_type": "text"
      },
      "source": [
        "## Features Collection\n",
        "\n",
        "이번 포스트에서는 맥락을 이용한다는 말을 했습니다. 여기서의 맥락은 앞, 뒤의 단어를 의미합니다. \n",
        "\n",
        "이번에는 단어가 들어오면 이를 피쳐로 바꾸어주는 함수를 정의할 것입니다. \n",
        "list of (word, pos, tag) 형식의 sentence 가 입력되면 이를 feature 로 변환해 넘겨줍니다. 각 단어의 피쳐를 뽑아내는 함수를 ***WordFeatures***를 통해 구현하겠습니다.  또한, 문장을 인코딩하는 함수를  ***SentFeatures*** 라고 칭하겠습니다. \n",
        "우리가 원하는 label인 개체명 tag는 ***SentTag***로 뽑아냅니다. \n",
        "\n",
        "\n",
        "피쳐의 수집 대상이 되는 단어들은 다음의 3가지 입니다. \n",
        " > w-1, w, w+1\n",
        "\n",
        "수집할 피쳐의 목록은 다음과 같습니다:\n",
        "- word.istitle() : 대문자로 시작\n",
        "- word.islower() : 모든 문자 소문자\n",
        "- word.isupper() : 모든 문자 대문자\n",
        "- len(word) : 단어 길이\n",
        "- pos : 품사 전체분류\n",
        "- pos[:2] : 품사 대분류\n",
        "\n",
        "해당 피쳐들은 밑에서 소개할 사이킷런의 CRF 구현 예제에서 선정한 목록을 참고했습니다. \n",
        "\n",
        "각 문장의 처음에는 시작지점을 의미하는 토근 **\"BOS\"**(Beginning of the sentence), \n",
        "끝에는 종료지점을 의미하는 토큰 **\"EOS\"**(End of the sentence)를 추가합니다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k13TtBUubbgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 단어의 피쳐 뽑아내기\n",
        "\n",
        "def WordFeatures(sent, i):\n",
        "    word = sent[i][0]\n",
        "    pos = sent[i][1]\n",
        "\n",
        "    # 대상 단어들에게서 뽑아낼 피쳐\n",
        "    features = {\n",
        "        'istitle': word.istitle(),\n",
        "        'islower': word.islower(), \n",
        "        'isupper': word.isupper(),\n",
        "        'length': len(word), \n",
        "        'pos': pos, \n",
        "        'pos[:2]': pos[:2]\n",
        "    }\n",
        "\n",
        "    if i>0:\n",
        "        context = sent[i-1][0]\n",
        "        posCxt = sent[i-1][1]\n",
        "\n",
        "        features.update({\n",
        "            '-1:istitle': context.istitle(),\n",
        "            '-1:islower': context.islower(),\n",
        "            '-1:isupper': context.isupper(), \n",
        "            '-1:length': len(context), \n",
        "            '-1:pos': posCxt, \n",
        "            '-1:pos[:2]':posCxt[:2]\n",
        "        }) \n",
        "\n",
        "    else: \n",
        "        features['BOS']=True\n",
        "\n",
        "    if i< len(sent)-1:\n",
        "        context = sent[i+1][0]\n",
        "        posCxt = sent[i+1][1]\n",
        "\n",
        "        features.update({\n",
        "            '+1:istitle': context.istitle(),\n",
        "            '+1:islower': context.islower(),\n",
        "            '+1:isupper': context.isupper(), \n",
        "            '+1:length': len(context), \n",
        "            '+1:pos': posCxt, \n",
        "            '+1:pos[:2]':posCxt[:2]\n",
        "        }) \n",
        "\n",
        "    else: \n",
        "        features['EOS']=True\n",
        "\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB77pvq-iYHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장 인코딩\n",
        "def SentFeatures(sent):\n",
        "    return [WordFeatures(sent, i) for i in range(len(sent))]\n",
        "\n",
        "# 개체명 레이블\n",
        "def SentTag(sent):\n",
        "    return [tag for word, pos, tag in sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V385LSHmknp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [SentFeatures(s) for s in sentences]\n",
        "y = [SentTag(s) for s in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DJGkUXdoEDQ",
        "colab_type": "code",
        "outputId": "e4a0c555-2227-481e-9c5b-615c356ec7f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "X[0][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'+1:islower': True,\n",
              " '+1:istitle': False,\n",
              " '+1:isupper': False,\n",
              " '+1:length': 2,\n",
              " '+1:pos': 'IN',\n",
              " '+1:pos[:2]': 'IN',\n",
              " 'BOS': True,\n",
              " 'islower': False,\n",
              " 'istitle': True,\n",
              " 'isupper': False,\n",
              " 'length': 9,\n",
              " 'pos': 'NNS',\n",
              " 'pos[:2]': 'NN'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHmDreGO2s9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X[:40000]\n",
        "X_test = X[40000:]\n",
        "\n",
        "y_train = y[:40000]\n",
        "y_test = y[40000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGYxS2WmuG-",
        "colab_type": "text"
      },
      "source": [
        "## CRF model 적용하기\n",
        "\n",
        "CRF를 직접 구현하기보다는, 사이킷런(sklearn-crfsuite)에서 제공하는 것을 사용하겠습니다. \n",
        "\n",
        "자세한 내용과 간단한 튜토리얼은 [다음](https://github.com/TeamHG-Memex/sklearn-crfsuite/blob/master/docs/CoNLL2002.ipynb)을 참고하세요. 위의 코드도 이를 참고했습니다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvEmkrb6o-fA",
        "colab_type": "code",
        "outputId": "c3858f9f-6d9e-4aad-f7c4-037598697f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "! pip install sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.12.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.38.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpaQkB9vmo7q",
        "colab_type": "code",
        "outputId": "2f054ec5-890a-4acb-8e80-7d209ff8ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "from sklearn_crfsuite import CRF\n",
        "\n",
        "crf = CRF(\n",
        "    algorithm='lbfgs', \n",
        "    c1=0.1, \n",
        "    c2=0.1, \n",
        "    max_iterations=100, \n",
        "    all_possible_transitions=True\n",
        ")\n",
        "\n",
        "crf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmDCJKwRpGw2",
        "colab_type": "text"
      },
      "source": [
        "L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization.\n",
        "\n",
        "마지막으로 **5-fold Cross Validation(교차 검증)**을 실행하도록 하겠습니다. \n",
        "\n",
        "해당 검증은 말 그대로 K개의 fold를 만들어서 진행하는 교차 검증 방법으로, 데이터의 크기가 적은 셋에 대한 정확도를 향상시키기 위한 목적으로 사용됩니다. \n",
        "\n",
        "일반적인 train, validation, test로 데이터를 나누는 방식은 데이터셋의 크기가 작은 경우 치명적이기 때문이죠. \n",
        "\n",
        "자세한 내용은 [이곳](https://nonmeyet.tistory.com/entry/KFold-Cross-Validation%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D-%EC%A0%95%EC%9D%98-%EB%B0%8F-%EC%84%A4%EB%AA%85)을 참고하세요. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydzkGSbroq56",
        "colab_type": "code",
        "outputId": "e40b8467-8886-4180-f2bb-7d72d533cded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn_crfsuite.metrics import flat_classification_report\n",
        "\n",
        "pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qufCMD0UqWF5",
        "colab_type": "text"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhvr1l2bqEKH",
        "colab_type": "code",
        "outputId": "00da479c-dfb2-4be2-84ed-eccf2bd393a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "report = flat_classification_report(y_pred=pred, y_true=y)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00       111\n",
            "       B-eve       0.25      0.03      0.06        89\n",
            "       B-geo       0.62      0.82      0.71      7695\n",
            "       B-gpe       0.78      0.77      0.78      3597\n",
            "       B-nat       0.00      0.00      0.00        53\n",
            "       B-org       0.64      0.46      0.53      4050\n",
            "       B-per       0.67      0.67      0.67      3568\n",
            "       B-tim       0.73      0.42      0.53      4099\n",
            "       I-art       0.00      0.00      0.00        65\n",
            "       I-eve       0.29      0.10      0.15        71\n",
            "       I-geo       0.54      0.48      0.51      1574\n",
            "       I-gpe       0.40      0.03      0.05        68\n",
            "       I-nat       0.00      0.00      0.00        22\n",
            "       I-org       0.57      0.59      0.58      3274\n",
            "       I-per       0.67      0.84      0.75      3734\n",
            "       I-tim       0.76      0.38      0.51      1236\n",
            "           O       0.98      0.99      0.99    184276\n",
            "\n",
            "    accuracy                           0.93    217582\n",
            "   macro avg       0.47      0.39      0.40    217582\n",
            "weighted avg       0.93      0.93      0.93    217582\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDhfj7amqksE",
        "colab_type": "code",
        "outputId": "4465f6cf-709b-475e-b57a-5759e9f8a334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "crf.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
              "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
              "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
              "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
              "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
              "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
              "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}